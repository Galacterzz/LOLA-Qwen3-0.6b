{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13851926,"sourceType":"datasetVersion","datasetId":8823683}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:11:52.017271Z","iopub.execute_input":"2025-11-24T14:11:52.017589Z","iopub.status.idle":"2025-11-24T14:11:52.029182Z","shell.execute_reply.started":"2025-11-24T14:11:52.017568Z","shell.execute_reply":"2025-11-24T14:11:52.028529Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/accuracy-qwen-lola/final_test.csv\n/kaggle/input/accuracy-qwen-lola/final_test_predictions.csv\n/kaggle/input/accuracy-qwen-lola/predicted_best_headlines.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# --- Load Data ---\n# 1. Ground Truth (Actual CTRs and Winner Flags)\ndf_ground_truth = pd.read_csv(\"/kaggle/input/accuracy-qwen-lola/final_test.csv\")\n\n# 2. Fine-Tuned Model Predictions (Selected Option IDs)\ndf_finetuned = pd.read_csv(\"/kaggle/input/accuracy-qwen-lola/predicted_best_headlines.csv\")\n\n# 3. Embedding Model Predictions (Predicted CTRs)\ndf_embedding = pd.read_csv(\"/kaggle/input/accuracy-qwen-lola/final_test_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:12:22.168987Z","iopub.execute_input":"2025-11-24T14:12:22.169499Z","iopub.status.idle":"2025-11-24T14:12:22.321157Z","shell.execute_reply.started":"2025-11-24T14:12:22.169473Z","shell.execute_reply":"2025-11-24T14:12:22.320433Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --- Helper Function: Get Ground Truth Map ---\n# Creates a dictionary {test_id: best_headline_text} and {test_id: best_option_number}\ndef get_ground_truth_map(df):\n    # Filter for the winning rows\n    winners = df[df['is_best'] == 1]\n    \n    # Map test_id -> best_option_number\n    id_to_option = winners.set_index('test_id')['option_number'].to_dict()\n    \n    # Map test_id -> best_headline_text\n    id_to_headline = winners.set_index('test_id')['headline'].to_dict()\n    \n    return id_to_option, id_to_headline\n\ngt_option_map, gt_headline_map = get_ground_truth_map(df_ground_truth)\nall_test_ids = list(gt_option_map.keys())\n\nprint(f\"Total Test Groups: {len(all_test_ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:12:50.229718Z","iopub.execute_input":"2025-11-24T14:12:50.229999Z","iopub.status.idle":"2025-11-24T14:12:50.249928Z","shell.execute_reply.started":"2025-11-24T14:12:50.229978Z","shell.execute_reply":"2025-11-24T14:12:50.249000Z"}},"outputs":[{"name":"stdout","text":"Total Test Groups: 3263\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Evaluation 1: Fine-Tuned Qwen Model ---\nprint(\"\\n--- Evaluating Fine-Tuned Qwen Model ---\")\n\ncorrect_ft = 0\ntotal_ft = 0\nmissing_ft = 0\n\nfor index, row in df_finetuned.iterrows():\n    tid = row['test_id']\n    pred_option = row['predicted_option']\n    \n    if tid in gt_option_map:\n        total_ft += 1\n        if pred_option == gt_option_map[tid]:\n            correct_ft += 1\n    else:\n        missing_ft += 1\n\naccuracy_ft = (correct_ft / total_ft) * 100 if total_ft > 0 else 0\nprint(f\"Fine-Tuned Accuracy: {accuracy_ft:.2f}% ({correct_ft}/{total_ft})\")\nif missing_ft > 0:\n    print(f\"Warning: {missing_ft} test IDs were missing from ground truth.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:13:19.613945Z","iopub.execute_input":"2025-11-24T14:13:19.614253Z","iopub.status.idle":"2025-11-24T14:13:19.755728Z","shell.execute_reply.started":"2025-11-24T14:13:19.614232Z","shell.execute_reply":"2025-11-24T14:13:19.754947Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Fine-Tuned Qwen Model ---\nFine-Tuned Accuracy: 35.70% (1165/3263)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# --- Evaluation 2: Embedding Model (Regression) ---\nprint(\"\\n--- Evaluating Embedding Model (Regression) ---\")\n\n# We need to group by test_id (which isn't in the embedding file explicitly, \n# so we must merge or assume order. \n# LOOKING AT THE FILES: 'final_test_predictions.csv' has 'headline' but NOT 'test_id'.\n# 'final_test.csv' has both. We must merge on 'headline' to recover 'test_id'.\n\n# Merge embedding predictions with ground truth to get test_id back\ndf_emb_merged = pd.merge(\n    df_embedding, \n    df_ground_truth[['headline', 'test_id', 'is_best']], \n    on='headline', \n    how='inner'\n)\n\n# Now find the predicted winner for each test_id based on max 'CTR_pred'\ngrouped_emb = df_emb_merged.groupby('test_id')\n\ncorrect_emb = 0\ntotal_emb = 0\n\nfor tid, group in grouped_emb:\n    total_emb += 1\n    \n    # Find the row with the highest PREDICTED CTR\n    predicted_winner_row = group.loc[group['CTR_pred'].idxmax()]\n    \n    # Check if this row is actually the best (is_best == 1)\n    # OR compare headlines text if is_best isn't reliable in the merge\n    if predicted_winner_row['is_best'] == 1:\n        correct_emb += 1\n    elif tid in gt_headline_map:\n        # Fallback: Compare headline text directly\n        if predicted_winner_row['headline'] == gt_headline_map[tid]:\n            correct_emb += 1\n\naccuracy_emb = (correct_emb / total_emb) * 100 if total_emb > 0 else 0\nprint(f\"Embedding Model Accuracy: {accuracy_emb:.2f}% ({correct_emb}/{total_emb})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:13:39.221282Z","iopub.execute_input":"2025-11-24T14:13:39.221605Z","iopub.status.idle":"2025-11-24T14:13:39.701824Z","shell.execute_reply.started":"2025-11-24T14:13:39.221584Z","shell.execute_reply":"2025-11-24T14:13:39.700931Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Embedding Model (Regression) ---\nEmbedding Model Accuracy: 42.79% (1383/3232)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- Comparison Summary ---\nprint(\"\\n\" + \"=\"*30)\nprint(\"ğŸ† FINAL RESULTS ğŸ†\")\nprint(\"=\"*30)\nprint(f\"Model A (Fine-Tuned LLM): {accuracy_ft:.2f}%\")\nprint(f\"Model B (Embedding Reg):  {accuracy_emb:.2f}%\")\n\nif accuracy_ft > accuracy_emb:\n    print(\"\\nâœ… The Fine-Tuned LLM performed better.\")\nelse:\n    print(\"\\nâœ… The Embedding Regression model performed better.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T14:14:04.136471Z","iopub.execute_input":"2025-11-24T14:14:04.136751Z","iopub.status.idle":"2025-11-24T14:14:04.142737Z","shell.execute_reply.started":"2025-11-24T14:14:04.136728Z","shell.execute_reply":"2025-11-24T14:14:04.141875Z"}},"outputs":[{"name":"stdout","text":"\n==============================\nğŸ† FINAL RESULTS ğŸ†\n==============================\nModel A (Fine-Tuned LLM): 35.70%\nModel B (Embedding Reg):  42.79%\n\nâœ… The Embedding Regression model performed better.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}